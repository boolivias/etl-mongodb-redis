{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DecimalType\n",
    "from functools import reduce\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "import datetime\n",
    "\n",
    "packages = ','.join([\n",
    "    'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1',\n",
    "    'com.redislabs:spark-redis_2.12:3.1.0'\n",
    "])\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"projeto-final-pmd-pedro-jean\") \\\n",
    "        .config(\"spark.mongodb.input.uri\",\"mongodb://mongo:27017/PMD2023.Mensagens_test\") \\\n",
    "        .config(\"spark.mongodb.output.uri\",\"mongodb://mongo:27017/PMD2023.Mensagens_test\") \\\n",
    "        .config(\"spark.redis.host\", \"redis\") \\\n",
    "        .config(\"spark.redis.port\", \"6379\") \\\n",
    "        .config(\"spark.redis.auth\", \"123\") \\\n",
    "        .config('spark.jars.packages', packages) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initDate = datetime.datetime(2022, 4, 12).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# df = spark.read.options(header='True', inferSchema='True', quote=\"\\\"\", escape=\"\\\"\").csv('./work/Mongo/')\n",
    "df = spark.read.options(header='True', inferSchema='True', quote=\"\\\"\", escape=\"\\\"\").csv('./work/Redis/day24.csv')\n",
    "\n",
    "treated = df.withColumn('currency', f.when((df.money.isNotNull()) & (df.money != '0'), f.regexp_replace('money', r'(\\D*)(\\d+(\\.|,)?\\d*)', '$1')).otherwise(None)) \\\n",
    "    .withColumn('money',  f.regexp_replace('money', r'(\\D*)(\\d+(\\.|,)?\\d*)', '$2')) \\\n",
    "    .withColumn('donated', (f.col('money') != '0')) \\\n",
    "    .withColumn('date', f.to_date(f.lit(initDate))) \\\n",
    "    .withColumn('id', f.expr(\"uuid()\"))\n",
    "\n",
    "treated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated.write.format(\"org.apache.spark.sql.redis\") \\\n",
    "    .option(\"table\", \"mensagens_test\") \\\n",
    "    .option(\"key.column\", \"id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "    \n",
    "treated.write.format('com.mongodb.spark.sql.DefaultSource').mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "time01 = time.time()\n",
    "\n",
    "redisDf = spark.read.format(\"org.apache.spark.sql.redis\").option(\"table\", \"mensagens_test\").option(\"key.column\", \"id\").load()\n",
    "redisDf.count()\n",
    "\n",
    "redisTime = time.time() - time01\n",
    "\n",
    "time02 = time.time()\n",
    "\n",
    "mongoDf = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "mongoDf.count()\n",
    "\n",
    "mongoTime = time.time() - time02\n",
    "\n",
    "print(redisDf.count())\n",
    "print(mongoDf.count())\n",
    "print(f\"Mongo execution time: {mongoTime}\")\n",
    "print(f\"Redis execution time: {redisTime}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
